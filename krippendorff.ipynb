{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.agreement import AnnotationTask\n",
    "from nltk.metrics import masi_distance\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import jaccard_score\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_level_mapping = {\n",
    "    'abbreviation without context':'lack of context',\n",
    "    'unclear intention': 'lack of context',\n",
    "    'write up': 'content generation',\n",
    "    'generate persona': 'content generation',\n",
    "    'exam reference': 'content generation',\n",
    "    'generate question': 'content generation',\n",
    "    'generate code template': 'content generation',\n",
    "    'code': 'content generation',\n",
    "    'generate test': 'content generation',\n",
    "    'elaboration': 'content generation',\n",
    "    'project assistance': 'content generation',\n",
    "    'summarise topic': 'summarisation',\n",
    "    'summarise literature': 'summarisation',\n",
    "    'definition': 'understand concept',\n",
    "    'understand': 'understand concept',\n",
    "    'application': 'understand concept',\n",
    "    'assistance in using application': 'it assistance',\n",
    "    'technical documentation': 'it assistance',\n",
    "    'set up': 'it assistance',\n",
    "    'debugging': 'programming assistance',\n",
    "    'code validation': 'programming assistance',\n",
    "    'code suggestion': 'programming assistance',\n",
    "    'writing refinement': 'language assistance',\n",
    "    'sensitive writing': 'language assistance',\n",
    "    'sutd-based information': 'search engine',\n",
    "    'retrieve data': 'search engine',\n",
    "    'find examples': 'search engine',\n",
    "    'industry knowledge': 'search engine',\n",
    "    'search engine query': 'search engine',\n",
    "    'avoid plagiarism detection': 'academic dishonesty',\n",
    "    'attempt to obtain answer for an assignment verbatim': 'academic dishonesty',\n",
    "    'possible academic dishonesty': 'academic dishonesty',\n",
    "    'sanity check': 'testing',\n",
    "    'testing capabilities': 'testing',\n",
    "    'gptlearn technical specification': 'clarify',\n",
    "    'role-playing': 'prompt engineering',\n",
    "    'establishing context': 'prompt engineering',\n",
    "    'structured output format': 'prompt engineering',\n",
    "    'idea validation': 'evaluation'\n",
    "}\n",
    "\n",
    "only_level1 = ['non-course related', 'follow up conversation', 'idea generation', 'malformed query', 'correcting model response', 'hallucination', 'oracle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_list(codes_list, code_dependency):\n",
    "    codes_list = [item.lower() for item in codes_list if item]\n",
    "    for code in codes_list:\n",
    "        if code in code_dependency.values() or code in only_level1:\n",
    "            pass\n",
    "        elif code in code_dependency.keys():\n",
    "            codes_list.append(code_dependency[code])\n",
    "        else:\n",
    "            print(f'Error: Unkown code -> {code} in the list {codes_list}')\n",
    "    return list(set(codes_list))\n",
    "\n",
    "all_data = []\n",
    "for file in os.listdir('ENCODED'):\n",
    "    if file.endswith('.xlsx') and not file.startswith('~'):\n",
    "        print(file)\n",
    "        df = pd.read_excel(os.path.join('ENCODED', file))\n",
    "        df['quotation'] = df['quotation'].str.replace(f'[{string.punctuation}]', '', regex=True)\n",
    "        df['quotation'] = df['quotation'].str.replace(r'\\s+', ' ', regex=True)\n",
    "        df['quotation'] = df['quotation'].str.replace('\\n', ' ')\n",
    "        df['quotation'] = df['quotation'].str.strip()\n",
    "        df = df.sort_values(by=['document', 'quotation'])\n",
    "        # Drop the unnecessary columns\n",
    "        df = df.drop(columns=['comment'])\n",
    "\n",
    "        df['codes'] = df['codes'].fillna('')\n",
    "        df['codes'] = df['codes'].astype(str)\n",
    "        df['codes'] = df['codes'].str.split(', ')\n",
    "        df['codes'] = df['codes'].apply(lambda x: modify_list(x, high_level_mapping))\n",
    "        df['codes'] = df['codes'].apply(sorted)\n",
    "        all_data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = all_data[0].merge(all_data[1], on=['document', 'quotation'], how='outer', suffixes=('_coder1', '_coder2'))\n",
    "merged_df = merged_df.merge(all_data[2], on=['document', 'quotation'], how='outer')\n",
    "merged_df['codes_coder3'] = merged_df['codes']\n",
    "merged_df = merged_df.drop(columns=['codes'])\n",
    "merged_df['codes_coder1'] = merged_df['codes_coder1'].fillna('[]').astype(str)\n",
    "merged_df['codes_coder2'] = merged_df['codes_coder2'].fillna('[]').astype(str)\n",
    "merged_df['codes_coder3'] = merged_df['codes_coder3'].fillna('[]').astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.sort_values(by=['document', 'quotation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_data = []\n",
    "for idx, row in merged_df.iterrows():\n",
    "    try:\n",
    "        for i in range(len(all_data)):\n",
    "            person = f'codes_coder{i+1}'\n",
    "            task_data.append((person, idx, frozenset(row[person])))\n",
    "    except:\n",
    "        for i in range(len(all_data)):\n",
    "            person = f'codes_coder{i+1}'\n",
    "            print(row[person], end=\" \")\n",
    "        print()\n",
    "    \n",
    "# Initialize AnnotationTask with masi_distance\n",
    "task = AnnotationTask(distance=masi_distance)\n",
    "\n",
    "# Load the task data\n",
    "task.load_array(task_data)\n",
    "\n",
    "# Compute Krippendorff's alpha\n",
    "alpha = task.alpha()\n",
    "print(f\"Krippendorff's alpha: {alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = 0.7\n",
    "selected_rows = []\n",
    "for idx, row in merged_df.iterrows():\n",
    "\n",
    "    coder1_labels = frozenset(row['codes_coder1'])\n",
    "    coder2_labels = frozenset(row['codes_coder2'])\n",
    "    coder3_labels = frozenset(row['codes_coder3'])\n",
    "    \n",
    "    distance = masi_distance(coder1_labels, coder2_labels)\n",
    "    if distance < criteria:\n",
    "        distance = masi_distance(coder1_labels, coder3_labels)\n",
    "        if distance < criteria:\n",
    "            distance = masi_distance(coder1_labels, coder3_labels)\n",
    "            selected_rows.append(row)\n",
    "low_distance_df = pd.DataFrame(selected_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_data = []\n",
    "for idx, row in low_distance_df.iterrows():\n",
    "    try:\n",
    "        for i in range(len(all_data)):\n",
    "            person = f'codes_coder{i+1}'\n",
    "            task_data.append((person, idx, frozenset(row[person])))\n",
    "    except:\n",
    "        for i in range(len(all_data)):\n",
    "            person = f'codes_coder{i+1}'\n",
    "            print(row[person], end=\" \")\n",
    "        print()\n",
    "    \n",
    "# Initialize AnnotationTask with masi_distance\n",
    "task = AnnotationTask(distance=masi_distance)\n",
    "\n",
    "# Load the task data\n",
    "task.load_array(task_data)\n",
    "\n",
    "# Compute Krippendorff's alpha\n",
    "alpha = task.alpha()\n",
    "print(f\"Krippendorff's alpha: {alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_distance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_distance_df.to_excel(\"low_distance_df.xlsx\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows = []\n",
    "for idx, row in merged_df.iterrows():\n",
    "\n",
    "    coder1_labels = frozenset(row['codes_coder1'])\n",
    "    coder2_labels = frozenset(row['codes_coder2'])\n",
    "    coder3_labels = frozenset(row['codes_coder3'])\n",
    "    \n",
    "    distance = masi_distance(coder1_labels, coder2_labels)\n",
    "    if distance >= criteria:\n",
    "        distance = masi_distance(coder1_labels, coder3_labels)\n",
    "        if distance >= criteria:\n",
    "            distance = masi_distance(coder1_labels, coder3_labels)\n",
    "            row['distance'] = distance\n",
    "            selected_rows.append(row)\n",
    "high_distance_df = pd.DataFrame(selected_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_distance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_distance_df.to_excel(\"high_distance_df.xlsx\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows = []\n",
    "for idx, row in merged_df.iterrows():\n",
    "    temp = [row['codes_coder1'], row['codes_coder2'], row['codes_coder3']]\n",
    "    if '[]' in temp:\n",
    "        selected_rows.append(row)\n",
    "missing_distance_df = pd.DataFrame(selected_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_distance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_distance_df.to_excel(\"missing_distance_df.xlsx\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = list(set(list(missing_distance_df['document'])))\n",
    "unique.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.metrics import agreement\n",
    "from nltk.metrics.distance import masi_distance\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "\n",
    "#(coder, item, label)\n",
    "data = [('inky','text01',frozenset(['love','gifts'])), \n",
    "      ('blinky','text01',frozenset([''])), \n",
    "      ('sue','text01',frozenset(['love','gifts'])), \n",
    "      ('inky','text02',frozenset(['slime','gaming'])), \n",
    "      ('blinky','text02',frozenset([''])), \n",
    "      ('sue','text02',frozenset(['slime','gaming']))]\n",
    "\n",
    "jaccard_task = nltk.AnnotationTask(distance=jaccard_distance)\n",
    "masi_task = nltk.AnnotationTask(distance=masi_distance)\n",
    "tasks = [jaccard_task, masi_task]\n",
    "for task in tasks:\n",
    "    task.load_array(data)\n",
    "    print(\"Statistics for dataset using {}\".format(task.distance))\n",
    "    print(\"C: {}\\nI: {}\\nK: {}\".format(task.C, task.I, task.K))\n",
    "    print(\"Pi: {}\".format(task.pi()))\n",
    "    print(\"Kappa: {}\".format(task.kappa()))\n",
    "    print(\"Multi-Kappa: {}\".format(task.multi_kappa()))\n",
    "    print(\"Alpha: {}\".format(task.alpha()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.metrics import agreement\n",
    "from nltk.metrics.distance import masi_distance\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "\n",
    "#(coder, item, label)\n",
    "data = [('inky','text01',frozenset(['love','gifts'])), \n",
    "      ('blinky','text01',frozenset(['love','gifts'])), \n",
    "      ('sue','text01',frozenset(['love','gifts'])), \n",
    "      ('inky','text02',frozenset(['slime','gaming'])), \n",
    "      ('blinky','text02',frozenset([\"\"])), \n",
    "      ('sue','text02',frozenset(['slime','gaming'])),\n",
    "      ('inky','text03',frozenset(['love','gifts'])), \n",
    "      ('blinky','text03',frozenset(['love','gifts'])), \n",
    "      ('sue','text03',frozenset(['love','gifts'])), \n",
    "      ('inky','text04',frozenset(['love','gifts'])), \n",
    "      ('blinky','text04',frozenset(['love','gifts'])), \n",
    "      ('sue','text04',frozenset(['love','gifts'])), ]\n",
    "\n",
    "jaccard_task = nltk.AnnotationTask(distance=jaccard_distance)\n",
    "masi_task = nltk.AnnotationTask(distance=masi_distance)\n",
    "tasks = [jaccard_task, masi_task]\n",
    "for task in tasks:\n",
    "    task.load_array(data)\n",
    "    print(\"Statistics for dataset using {}\".format(task.distance))\n",
    "    print(\"C: {}\\nI: {}\\nK: {}\".format(task.C, task.I, task.K))\n",
    "    print(\"Pi: {}\".format(task.pi()))\n",
    "    print(\"Kappa: {}\".format(task.kappa()))\n",
    "    print(\"Multi-Kappa: {}\".format(task.multi_kappa()))\n",
    "    print(\"Alpha: {}\".format(task.alpha()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
