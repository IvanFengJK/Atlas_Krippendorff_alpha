{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.agreement import AnnotationTask\n",
    "from nltk.metrics import masi_distance\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import jaccard_score\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_level_mapping = {\n",
    "    'abbreviation without context':'lack of context',\n",
    "    'unclear intention': 'lack of context',\n",
    "    'write up': 'content generation',\n",
    "    'generate persona': 'content generation',\n",
    "    'exam reference': 'content generation',\n",
    "    'generate question': 'content generation',\n",
    "    'generate code template': 'content generation',\n",
    "    'code': 'content generation',\n",
    "    'generate test': 'content generation',\n",
    "    'elaboration': 'content generation',\n",
    "    'project assistance': 'content generation',\n",
    "    'summarise topic': 'summarisation',\n",
    "    'summarise literature': 'summarisation',\n",
    "    'definition': 'understand concept',\n",
    "    'understand': 'understand concept',\n",
    "    'application': 'understand concept',\n",
    "    'assistance in using application': 'it assistance',\n",
    "    'technical documentation': 'it assistance',\n",
    "    'set up': 'it assistance',\n",
    "    'debugging': 'programming assistance',\n",
    "    'code validation': 'programming assistance',\n",
    "    'code suggestion': 'programming assistance',\n",
    "    'writing refinement': 'language assistance',\n",
    "    'sensitive writing': 'language assistance',\n",
    "    'sutd-based information': 'search engine',\n",
    "    'retrieve data': 'search engine',\n",
    "    'find examples': 'search engine',\n",
    "    'industry knowledge': 'search engine',\n",
    "    'search engine query': 'search engine',\n",
    "    'avoid plagiarism detection': 'academic dishonesty',\n",
    "    'attempt to obtain answer for an assignment verbatim': 'academic dishonesty',\n",
    "    'possible academic dishonesty': 'academic dishonesty',\n",
    "    'sanity check': 'testing',\n",
    "    'testing capabilities': 'testing',\n",
    "    'gptlearn technical specification': 'clarify',\n",
    "    'role-playing': 'prompt engineering',\n",
    "    'establishing context': 'prompt engineering',\n",
    "    'structured output format': 'prompt engineering',\n",
    "    'idea validation': 'evaluation'\n",
    "}\n",
    "\n",
    "only_level1 = ['non-course related', 'follow up conversation', 'idea generation', 'malformed query', 'correcting model response', 'hallucination', 'oracle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_list(codes_list, code_dependency):\n",
    "    codes_list = [item.lower() for item in codes_list if item]\n",
    "    for code in codes_list:\n",
    "        if code in code_dependency.values() or code in only_level1:\n",
    "            pass\n",
    "        elif code in code_dependency.keys():\n",
    "            codes_list.append(code_dependency[code])\n",
    "        else:\n",
    "            print(f'Error: Unkown code -> {code} in the list {codes_list}')\n",
    "    return list(set(codes_list))\n",
    "\n",
    "all_data = []\n",
    "for file in os.listdir('ENCODED'):\n",
    "    if file.endswith('.xlsx') and not file.startswith('~'):\n",
    "        print(file)\n",
    "        df = pd.read_excel(os.path.join('ENCODED', file))\n",
    "        df['quotation'] = df['quotation'].str.replace(f'[{string.punctuation}]', '', regex=True)\n",
    "        df['quotation'] = df['quotation'].str.replace('\\n', '')\n",
    "        df['quotation'] = df['quotation'].str.replace(r'\\s+', '', regex=True)\n",
    "        df['quotation'] = df['quotation'].str.strip()\n",
    "        df['quotation'] = df['quotation'].str.lower()\n",
    "        df = df.sort_values(by=['document', 'quotation'])\n",
    "        # Drop the unnecessary columns\n",
    "        df = df.drop(columns=['comment'])\n",
    "\n",
    "        df['codes'] = df['codes'].fillna('')\n",
    "        df['codes'] = df['codes'].astype(str)\n",
    "        df['codes'] = df['codes'].str.split(', ')\n",
    "        df['codes'] = df['codes'].apply(lambda x: modify_list(x, high_level_mapping))\n",
    "        df['codes'] = df['codes'].apply(sorted)\n",
    "        all_data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = all_data[0].merge(all_data[1], on=['document', 'quotation'], how='outer', suffixes=('_coder1', '_coder2'))\n",
    "merged_df = merged_df.merge(all_data[2], on=['document', 'quotation'], how='outer')\n",
    "merged_df['codes_coder3'] = merged_df['codes']\n",
    "merged_df = merged_df.drop(columns=['codes'])\n",
    "merged_df['codes_coder1'] = merged_df['codes_coder1'].fillna('[]').astype(str)\n",
    "merged_df['codes_coder2'] = merged_df['codes_coder2'].fillna('[]').astype(str)\n",
    "merged_df['codes_coder3'] = merged_df['codes_coder3'].fillna('[]').astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.sort_values(by=['document', 'quotation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_data = []\n",
    "for idx, row in merged_df.iterrows():\n",
    "    try:\n",
    "        for i in range(len(all_data)):\n",
    "            person = f'codes_coder{i+1}'\n",
    "            task_data.append((person, idx, frozenset(row[person])))\n",
    "    except:\n",
    "        for i in range(len(all_data)):\n",
    "            person = f'codes_coder{i+1}'\n",
    "            print(row[person], end=\" \")\n",
    "        print()\n",
    "    \n",
    "# Initialize AnnotationTask with masi_distance\n",
    "task = AnnotationTask(distance=masi_distance)\n",
    "\n",
    "# Load the task data\n",
    "task.load_array(task_data)\n",
    "\n",
    "# Compute Krippendorff's alpha\n",
    "alpha = task.alpha()\n",
    "print(f\"Krippendorff's alpha: {alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_alpha(df):\n",
    "    task_data = []\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            for i in range(len(all_data)):\n",
    "                person = f'codes_coder{i+1}'\n",
    "                task_data.append((person, idx, frozenset(row[person])))\n",
    "        except:\n",
    "            for i in range(len(all_data)):\n",
    "                person = f'codes_coder{i+1}'\n",
    "                print(row[person], end=\" \")\n",
    "            print()\n",
    "        \n",
    "    # Initialize AnnotationTask with masi_distance\n",
    "    task = AnnotationTask(distance=masi_distance)\n",
    "\n",
    "    # Load the task data\n",
    "    task.load_array(task_data)\n",
    "\n",
    "    # Compute Krippendorff's alpha\n",
    "    alpha = task.alpha()\n",
    "    print(f\"Krippendorff's alpha: {alpha}\")\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = 0.5\n",
    "selected_rows = []\n",
    "rejected_rows = []\n",
    "for idx, row in merged_df.iterrows():\n",
    "\n",
    "    coder1_labels = frozenset(row['codes_coder1'])\n",
    "    coder2_labels = frozenset(row['codes_coder2'])\n",
    "    coder3_labels = frozenset(row['codes_coder3'])\n",
    "\n",
    "    distance1 = masi_distance(coder2_labels, coder1_labels)\n",
    "    if distance1 > criteria:\n",
    "        distance2 = masi_distance(coder2_labels, coder3_labels)\n",
    "        if distance2 > criteria:\n",
    "            distance3 = masi_distance(coder1_labels, coder3_labels)\n",
    "            if distance3 < criteria-0.1:\n",
    "                row['distance'] = (distance1+distance2)/2\n",
    "                selected_rows.append(row)\n",
    "                continue\n",
    "    rejected_rows.append(row)\n",
    "                \n",
    "high_distance_df = pd.DataFrame(selected_rows)\n",
    "low_distance_df = pd.DataFrame(rejected_rows)\n",
    "assert high_distance_df.shape[0] + low_distance_df.shape[0] == merged_df.shape[0]\n",
    "calculate_alpha(high_distance_df)\n",
    "calculate_alpha(low_distance_df)\n",
    "calculate_alpha(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_distance_df.to_excel(\"high_distance_df_daniel.xlsx\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
